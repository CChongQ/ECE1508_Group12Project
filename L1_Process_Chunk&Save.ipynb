{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environmetn Setup"
      ],
      "metadata": {
        "id": "JGEI9OjIrbA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCc9CdAkexQA"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"langchain[openai]\" langchain-core langgraph langchain-text-splitters langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu jq"
      ],
      "metadata": {
        "id": "EIJKBWd_fQrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain-chroma>=0.1.2\""
      ],
      "metadata": {
        "id": "3vIDQZvnx96M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "ktKdUHx9yEzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "import faiss\n",
        "import re\n",
        "import getpass\n",
        "import os\n",
        "import time\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Qy3MpCwZFR8L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_text_splitters import HTMLSectionSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain.chains import create_extraction_chain\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain import hub\n",
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n"
      ],
      "metadata": {
        "id": "ClKCfdTSGZgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "swkkAqnxxNkj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ],
      "metadata": {
        "id": "YS1gRamHfY1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214b558d-e7f2-4a0c-d41f-080a7b993ad4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd  /content/drive/MyDrive/ECE1508_Project/Codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKEpu0O6fgMx",
        "outputId": "2f38517f-dcd7-45f2-cf9c-a75ad54bce4a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ECE1508_Project/Codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "s5eNbOcwD6o9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Test Doc"
      ],
      "metadata": {
        "id": "MuhooPOlrhK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata_func(example: dict, _: dict) -> dict:\n",
        "    return {\n",
        "        \"question_text\": example.get(\"question_text\"),\n",
        "        \"Title\": example.get(\"title\", \"Untitled\")\n",
        "    }"
      ],
      "metadata": {
        "id": "cFP1-rLTgr11"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(file_path):\n",
        "  loader=JSONLoader(\n",
        "    file_path=file_path,\n",
        "    jq_schema=\".[]\",\n",
        "    content_key=\"document_text\",\n",
        "    metadata_func=metadata_func\n",
        "  )\n",
        "  documents=loader.load()\n",
        "\n",
        "  return documents"
      ],
      "metadata": {
        "id": "AKoIS4oc9LFJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Store Helpers"
      ],
      "metadata": {
        "id": "zIcK9WKO48gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_faiss_vec_store(elemnts_to_emb, folder_name):\n",
        "#   embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "#   vectorstore = FAISS.from_documents(elemnts_to_emb, embedding=embeddings)\n",
        "#   vectorstore.save_local(folder_name)\n",
        "#   return vectorstore"
      ],
      "metadata": {
        "id": "VkWWcJwu4_mh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriver Helpers"
      ],
      "metadata": {
        "id": "o7-Cx6fN6Off"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the top K contents\n",
        "def retrieve_section(in_retriever,query):\n",
        "  results=in_retriever.get_relevant_documents(query)\n",
        "  if not results:\n",
        "    return None\n",
        "\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "b5gC4gab6QCC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run retriver for the input query\n",
        "def get_retrieve_section(in_retriever,in_query,top_k):\n",
        "  print(f\"Retrieving answer for query: {in_query}\")\n",
        "  relevant_sections=retrieve_section(in_retriever,in_query,top_k)\n",
        "  return relevant_sections"
      ],
      "metadata": {
        "id": "z-N6Hacn6SPI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Level 1 Helpers"
      ],
      "metadata": {
        "id": "XrOFCx9fqrn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Document Chunking**"
      ],
      "metadata": {
        "id": "kiNotLnAurs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_element_chunk(split_header_list,doc_to_chunk):\n",
        "\n",
        "  #Wrap the the original HTML content in a temporary Document object\n",
        "  html_doc = Document(page_content=doc_to_chunk.page_content, metadata=doc_to_chunk.metadata)\n",
        "\n",
        "  #Only split the HTML part\n",
        "  html_splitter = HTMLSectionSplitter(headers_to_split_on=split_header_list)\n",
        "  elements_chunked = html_splitter.split_documents([html_doc])\n",
        "  return elements_chunked\n"
      ],
      "metadata": {
        "id": "927QAUBXtetL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 1 Chunking & Save to Vector\n"
      ],
      "metadata": {
        "id": "E8JCYikZ7Vi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector stpre folder path\n",
        "#Recheck pwd\n",
        "!ls\n",
        "L1_vector_folder = 'L1_vector_final'\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI2GBr_cECn7",
        "outputId": "5caf5bcf-a41d-4a55-9697-cf5efbd63ebc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Archive\t\t Evaluation.ipynb\t        Proposition_Light.ipynb\n",
            " Baseline.ipynb\t\t gold_test_file_30.json         Proposition_Sample.ipynb\n",
            " Baseline_Use_L1.ipynb\t'L1_Process_Chunk&Save.ipynb'   rag_sw_ver2.ipynb\n",
            " Baseline_vector\t L1_vector\t\t        rag_sw_ver3.ipynb\n",
            " dense_pack\t\t L2_vector_prop\t\t        test_single_doc.json\n",
            " evaluation\t\t Proposition_Complete.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path=\"gold_test_file_30.json\"\n",
        "test_documents = load_documents(file_path)\n",
        "print(f\"{len(test_documents)} Documents\")\n"
      ],
      "metadata": {
        "id": "HwvSRP-o8zCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8ac9ff-0e17-41fe-fff3-bd1b46a3b12d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 Documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: L1 basic chunking\n",
        "\n",
        "Chunk all documents in the input json and save into vector database"
      ],
      "metadata": {
        "id": "Dq01zDhb_5e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L1_process_document(doc):\n",
        "  headers_to_split_on = [\n",
        "    (\"h1\", \"Header 1\"),\n",
        "    (\"h2\", \"Header 2\"),\n",
        "    (\"h3\", \"Header 3\"),\n",
        "  ]\n",
        "\n",
        "  all_chunks = []\n",
        "  for idx,eachDoc in enumerate(doc):\n",
        "      chunks = get_element_chunk(headers_to_split_on, eachDoc)\n",
        "      all_chunks.extend(chunks)\n",
        "      print(f\"Split document {idx+1} into {len(chunks)} sub-documents.\")\n",
        "      #print(f\"Example 1: {chunks[1]}\")\n",
        "\n",
        "  #Embed and Vector store\n",
        "  #L1_vectorstore=create_faiss_vec_store(all_chunks,L1_vector_folder)\n",
        "\n",
        "  # Embed and save to Chroma DB\n",
        "  if os.path.exists(L1_vector_folder):\n",
        "    shutil.rmtree(L1_vector_folder)\n",
        "    time.sleep(1)\n",
        "\n",
        "  L1_vectorstore = Chroma.from_documents(documents=all_chunks,\n",
        "                                      embedding=embeddings ,\n",
        "                                      persist_directory=L1_vector_folder)\n",
        "\n",
        "  print(f\"{len(doc)} documents {len(all_chunks)} chunks sucessfully processed and saved to {L1_vector_folder}\")\n",
        "\n",
        "  return L1_vectorstore\n",
        "\n"
      ],
      "metadata": {
        "id": "Mjd2YDe39G83"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1_vectorstore = L1_process_document(test_documents)"
      ],
      "metadata": {
        "id": "o8iy3A38AYi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53d628a-e48e-42fe-97d7-173169ee259b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split document 1 into 33 sub-documents.\n",
            "Split document 2 into 20 sub-documents.\n",
            "Split document 3 into 21 sub-documents.\n",
            "Split document 4 into 7 sub-documents.\n",
            "Split document 5 into 47 sub-documents.\n",
            "Split document 6 into 41 sub-documents.\n",
            "Split document 7 into 24 sub-documents.\n",
            "Split document 8 into 19 sub-documents.\n",
            "Split document 9 into 19 sub-documents.\n",
            "Split document 10 into 13 sub-documents.\n",
            "Split document 11 into 31 sub-documents.\n",
            "Split document 12 into 12 sub-documents.\n",
            "Split document 13 into 23 sub-documents.\n",
            "Split document 14 into 42 sub-documents.\n",
            "Split document 15 into 16 sub-documents.\n",
            "Split document 16 into 38 sub-documents.\n",
            "Split document 17 into 91 sub-documents.\n",
            "Split document 18 into 13 sub-documents.\n",
            "Split document 19 into 27 sub-documents.\n",
            "Split document 20 into 15 sub-documents.\n",
            "Split document 21 into 33 sub-documents.\n",
            "Split document 22 into 13 sub-documents.\n",
            "Split document 23 into 25 sub-documents.\n",
            "Split document 24 into 22 sub-documents.\n",
            "Split document 25 into 39 sub-documents.\n",
            "Split document 26 into 43 sub-documents.\n",
            "Split document 27 into 29 sub-documents.\n",
            "Split document 28 into 14 sub-documents.\n",
            "Split document 29 into 24 sub-documents.\n",
            "Split document 30 into 14 sub-documents.\n",
            "30 documents 808 chunks sucessfully processed and saved to L1_vector_final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Load\n",
        "print(L1_vector_folder)\n",
        "L1_vectorstore_testload = Chroma(\n",
        "    persist_directory=L1_vector_folder,\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "#Verify local load result\n",
        "total_docs = L1_vectorstore_testload._collection.count()\n",
        "if total_docs > 0:\n",
        "    print(f\"Vectorstore contains {total_docs} documents\")\n",
        "else:\n",
        "    print(\"Vectorstore is empty\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOlKej2SZBdU",
        "outputId": "1cd1d5dc-21c3-483a-e77a-8e91f0f8642b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1_vector_final\n",
            "Vectorstore contains 808 documents\n"
          ]
        }
      ]
    }
  ]
}